{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb05362b",
   "metadata": {},
   "source": [
    "# Task 3 - Model Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dca8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from sklearn.metrics import f1_score, confusion_matrix, average_precision_score\n",
    "import os\n",
    "import sys\n",
    "import ipaddress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sys.path.append(os.path.abspath(\"../Shap_Analysis\"))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, average_precision_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439266ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc2e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Shap_Analysis.shap_utils import load_model, compute_shap_values\n",
    "from Shap_Analysis.shap_visuals import plot_summary, plot_force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa8d9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_shap_pipeline():\n",
    "    try:\n",
    "        # Load cleaned dataset (already preprocessed & scaled)\n",
    "        df = pd.read_csv(\"Data/cleaned_fraud.csv\")\n",
    "\n",
    "        # Features and label\n",
    "        X = df.drop(columns=[\"class\"])\n",
    "        y = df[\"class\"]\n",
    "\n",
    "        # Sample for SHAP to avoid memory issues\n",
    "        X_sample, _, y_sample, _ = train_test_split(X, y, stratify=y, test_size=0.99, random_state=42)\n",
    "\n",
    "        # Load trained model\n",
    "        model = load_model(\"Models/xgboost_model.pkl\")\n",
    "\n",
    "        # SHAP computation\n",
    "        explainer, shap_values = compute_shap_values(model, X_sample)\n",
    "\n",
    "        # Visualizations\n",
    "        plot_summary(shap_values, X_sample, save_path=\"Shap_Analysis/shap_summary\")\n",
    "        plot_force(explainer, shap_values, row_idx=0, save_path=\"Shap_Analysis/force_plot\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57bc6ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline error: Model not found at Models/xgboost_model.pkl\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_shap_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
